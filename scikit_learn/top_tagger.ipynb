{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from common import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.tree as tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from baseTagger import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_csv(orifilename, outfilename, forceRedo = False):\n",
    "    if not os.path.isfile(outfilename) or forceRedo:\n",
    "        if not os.path.isfile(orifilename):\n",
    "            print('orifilename : {} does not exist!'.format(orifilename))\n",
    "            sys.exit(1)        \n",
    "        df_ori = pd.read_csv(orifilename, compression='gzip')\n",
    "        df = df_ori[(df_ori['cand_dRMax']<1.5) & (df_ori['cand_m']>100) & (df_ori['cand_m']<250)]\n",
    "        to_drop = [x for x in df_ori.columns if 'Unnamed' in x]\n",
    "        df = df.drop(to_drop, axis=1)\n",
    "        df.to_csv(outfilename)\n",
    "    else:\n",
    "        df = pd.read_csv(outfilename)\n",
    "        to_drop = [x for x in df.columns if 'Unnamed' in x]\n",
    "        df = df.drop(to_drop, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = get_csv('training.csv', 'dRMax_LE_1p5_m_in_100_250_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nSig_wt = df[df['answer']==1].weight.sum()\n",
    "nBkg_wt = df[df['answer']==0].weight.sum()\n",
    "weight = nSig_wt/nBkg_wt\n",
    "df.loc[df['answer']==0, 'weight'] *= weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_shuffled = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "npyInputData = np.array(df_shuffled.ix[:, :'j3_QGL'])\n",
    "npyInputAnswer = np.array(df_shuffled.ix[:, 'answer'])\n",
    "npyInputWgts = np.array(df_shuffled.ix[:, 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=14, n_jobs=4)\n",
    "clf = clf.fit(npyInputData, npyInputAnswer, npyInputWgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"TrainingOutput.pkl\",'wb')\n",
    "out = pickle.dump(clf, fileObject)\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "listToGet = df_shuffled.columns[:df_shuffled.columns.get_loc('j3_QGL')+1]\n",
    "feature_importance = clf.feature_importances_\n",
    "feature_names = np.array(listToGet)\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "_ = plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "_ = plt.yticks(pos, feature_names[sorted_idx])\n",
    "_ = plt.xlabel('Relative Importance')\n",
    "_ = plt.title('Variable Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "featureImportanceandNames = list(zip(feature_names, feature_importance))\n",
    "print([featureImportanceandNames[a] for a in sorted_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val_df = get_csv('validation.csv', 'dRMax_LE_1p5_m_in_100_250_validation.csv')\n",
    "val_npInputList = np.array(val_df.ix[:, :'j3_QGL'])\n",
    "val_npInputAnswers = np.array(val_df.ix[:, 'answer'])\n",
    "val_npInputList_ttbar = np.array(val_df[val_df['procTypes']=='ttbar'].ix[:, :'j3_QGL'])\n",
    "val_npInputAnswers_ttbar = np.array(val_df[val_df['procTypes']=='ttbar'].ix[:, 'answer'])\n",
    "val_npInputList_zinv = np.array(val_df[val_df['procTypes']=='zinv'].ix[:, :'j3_QGL'])\n",
    "val_npInputAnswers_zinv = np.array(val_df[val_df['procTypes']=='zinv'].ix[:, 'answer'])\n",
    "val_slimNpData0_ttbar = val_npInputList_ttbar[val_npInputAnswers_ttbar==0]\n",
    "val_slimNpData1_ttbar = val_npInputList_ttbar[val_npInputAnswers_ttbar==1]\n",
    "val_slimNpData_zinv = val_npInputList_zinv[val_npInputAnswers_zinv==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val_output = clf.predict_proba(val_npInputList)[:,1]\n",
    "val_df['disc'] = val_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import fractional_matrix_power\n",
    "def diagElements(m):\n",
    "    size = m.shape[0]\n",
    "    return np.matrix(np.diag([m[i, i] for i in range(size)]))\n",
    "\n",
    "def corrMat(m):\n",
    "    sqrt_diag = fractional_matrix_power(diagElements(m), -0.5)\n",
    "    return np.array(sqrt_diag * m  * sqrt_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ecv = EmpiricalCovariance()\n",
    "_=ecv.fit(val_slimNpData0_ttbar)\n",
    "corr0_ttbar = corrMat(np.matrix(ecv.covariance_))\n",
    "_=ecv.fit(val_slimNpData1_ttbar)\n",
    "corr1_ttbar = corrMat(np.matrix(ecv.covariance_))\n",
    "_=ecv.fit(val_slimNpData_zinv)\n",
    "corr_zinv = corrMat(np.matrix(ecv.covariance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_=plt.matshow(corr0_ttbar, cmap=plt.cm.seismic, vmin = -1, vmax = 1)\n",
    "_=plt.xticks(range(len(listToGet)), listToGet, rotation='vertical')\n",
    "_=plt.yticks(range(len(listToGet)), listToGet)\n",
    "_=plt.colorbar(orientation='vertical')\n",
    "plt.savefig(\"feature_corrolation_ttbar_nomatch.png\")\n",
    "\n",
    "_=plt.matshow(corr1_ttbar, cmap=plt.cm.seismic, vmin = -1, vmax = 1)\n",
    "_=plt.xticks(range(len(listToGet)), listToGet, rotation='vertical')\n",
    "_=plt.yticks(range(len(listToGet)), listToGet)\n",
    "_=plt.colorbar(orientation='vertical')\n",
    "plt.savefig(\"feature_corrolation_ttbar_match.png\")\n",
    "\n",
    "_=plt.matshow(corr_zinv, cmap=plt.cm.seismic, vmin = -1, vmax = 1)\n",
    "_=plt.xticks(range(len(listToGet)), listToGet, rotation='vertical')\n",
    "_=plt.yticks(range(len(listToGet)), listToGet)\n",
    "_=plt.colorbar(orientation='vertical')\n",
    "plt.savefig(\"feature_corrolation_Znunu.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_df['passBaseTagger'] = val_df.apply(baseTaggerReqs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sr_cuts = (val_df['Njet']>=4) & (val_df['MET']>200) & (val_df['cand_dRMax']<1.5)\n",
    "baseTagger_fpr_tpr = val_df[sr_cuts].groupby(by=['answer', 'passBaseTagger'])['sampleWgt'].sum()\n",
    "baseTagger_fpr_tpr\n",
    "tp_base = baseTagger_fpr_tpr.loc[1, True]\n",
    "fp_base = baseTagger_fpr_tpr.loc[0, True]\n",
    "tn_base = baseTagger_fpr_tpr.loc[0, False]\n",
    "fn_base = baseTagger_fpr_tpr.loc[1, False]\n",
    "tpr_base = tp_base/(tp_base + fn_base)\n",
    "fpr_base = fp_base/(fp_base + tn_base)\n",
    "\n",
    "precision_base = tp_base/(tp_base + fp_base)\n",
    "recall_base = tp_base/(tp_base + fn_base)\n",
    "\n",
    "fscore_base = 2*precision_base*recall_base/(precision_base+recall_base)\n",
    "\n",
    "fpr_base, tpr_base, precision_base, recall_base, fscore_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val_npInputAnswers_sel = val_npInputAnswers[np.array(sr_cuts)]\n",
    "val_output_sel = val_output[np.array(sr_cuts)]\n",
    "\n",
    "precision, recall, thresholds_pr = precision_recall_curve(val_npInputAnswers_sel, val_output_sel)\n",
    "fscore = 2*precision*recall/(precision + recall)\n",
    "average_precision = average_precision_score(val_npInputAnswers_sel, val_output_sel)\n",
    "fpr, tpr, thresholds_roc = roc_curve(val_npInputAnswers_sel, val_output_sel, sample_weight=np.array(val_df.loc[sr_cuts,'sampleWgt']))\n",
    "roc_auc = auc(tpr, fpr)\n",
    "_ = plt.plot(fpr, tpr, color = 'darkorange', label = 'ROC curve (area = %0.2f)'%roc_auc)\n",
    "_ = plt.plot([0, 1], [0, 1], color='navy', linestyle = '--')\n",
    "_ = plt.xlim([0.0, 1.0])\n",
    "_ = plt.ylim([0.0, 1.05])\n",
    "_ = plt.xlabel('False Positive Rate')\n",
    "_ = plt.ylabel('True Positive Rate')\n",
    "_ = plt.title('ROC')\n",
    "_ = plt.legend(loc='lower right')\n",
    "_ = plt.plot(fpr_base, tpr_base, 'or')\n",
    "plt.show()\n",
    "_=plt.plot(recall, precision, color = 'darkorange')\n",
    "_=plt.xlim([0.0, 1.0])\n",
    "_=plt.ylim([0.0, 1.05])\n",
    "_=plt.xlabel('recall')\n",
    "_=plt.ylabel('precision')\n",
    "_=plt.title('precision-recall')\n",
    "_=plt.plot(precision_base, recall_base, 'or')\n",
    "plt.show()\n",
    "# Get the cut value for where we have same tpr as the tpr_base\n",
    "idx_same_tpr = -1\n",
    "idx_same_fpr = -1\n",
    "for i in range(len(fpr)-1):\n",
    "    if(tpr[i]<tpr_base and tpr[i+1]>=tpr_base):\n",
    "        idx_same_tpr = i+1\n",
    "    if(fpr[i]<fpr_base and fpr[i+1]>=fpr_base):\n",
    "        idx_same_fpr = i+1\n",
    "idx_same_fscore = -1\n",
    "idx_max_fscore = -1\n",
    "for i in range(len(fscore)-1):\n",
    "    if(fscore[i]<fscore_base and fscore[i+1]>=fscore_base):\n",
    "        idx_same_fscore = i+1\n",
    "    if idx_max_fscore == -1 or (fscore[idx_max_fscore]<fscore[i]):\n",
    "        idx_max_fscore = i\n",
    "# We want a high recall (tpr) working point (as high as the base tagger)\n",
    "mva_cut = thresholds_roc[idx_same_tpr]\n",
    "alt_mva_cut = thresholds_roc[idx_same_fpr]\n",
    "print('baseTagger tpr : {}  fpr : {}  fscore : {} --> precision : {}  recall : {}'.format(tpr_base, fpr_base, fscore_base, precision_base, recall_base))\n",
    "print('mva (same_tpr) tpr : {}  fpr : {}  cut : {}'.format(tpr[idx_same_tpr], fpr[idx_same_tpr], mva_cut))\n",
    "print('mva (same_fpr) tpr : {}  fpr : {}  cut : {}'.format(tpr[idx_same_fpr], fpr[idx_same_fpr], alt_mva_cut))\n",
    "print('mva (same_fscore) fscore : {}  precision : {}  recall : {}  cut : {}'.format(fscore[idx_same_fscore], precision[idx_same_fscore], recall[idx_same_fscore], thresholds_pr[idx_same_fscore]))\n",
    "print('mva (max_fscore) fscore : {}  precision : {}  recall : {}  cut : {}'.format(fscore[idx_max_fscore], precision[idx_max_fscore], recall[idx_max_fscore], thresholds_pr[idx_max_fscore]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sig_val_output = val_output[val_npInputAnswers==1]\n",
    "bkg_val_output = val_output[val_npInputAnswers==0]\n",
    "y_sig, x_sig, _=plt.hist(sig_val_output, range = (0, 1.0), normed = True, color = 'red', bins = 100, histtype='step')\n",
    "y_bkg, x_bkg, _=plt.hist(bkg_val_output, range = (0, 1.0), normed = True, color = 'blue', bins = 100, histtype='step')\n",
    "_=plt.plot([mva_cut, mva_cut], [0, max(y_sig.max(), y_bkg.max())], color='navy', linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped_val_df = val_df.groupby(['evtNum', 'procTypes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sr_grouped_baseTagger = grouped_val_df.apply(resolveOverlapHEP)\n",
    "df_grouped_baseTagger = sr_grouped_baseTagger.reset_index()\n",
    "df_grouped_baseTagger =df_grouped_baseTagger.rename(columns={0:'baseTagger'})\n",
    "val_df_baseTagger = pd.merge(val_df, df_grouped_baseTagger, how='outer', left_on = ['evtNum', 'procTypes'], \n",
    "         right_on = ['evtNum', 'procTypes'])\n",
    "val_df_baseTagger.index = val_df.index\n",
    "sr_grouped_mvaTagger = grouped_val_df.apply(resolveOverlap, mva_cut)\n",
    "df_grouped_mvaTagger = sr_grouped_mvaTagger.reset_index()\n",
    "df_grouped_mvaTagger = df_grouped_mvaTagger.rename(columns={0:'mvaTagger'})\n",
    "val_df_taggers = pd.merge(val_df_baseTagger, df_grouped_mvaTagger, \n",
    "                                          how='outer', left_on=['evtNum', 'procTypes'],\n",
    "                                         right_on=['evtNum', 'procTypes'])\n",
    "val_df_taggers.index = val_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_df_taggers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
